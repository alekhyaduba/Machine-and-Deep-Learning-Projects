# -*- coding: utf-8 -*-
"""Noisy_MNIST_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14ssc21PBMMQNiIWF29reUCwqDzw02gjb

#Train the model

##Step 1: Load the data.

Upload the images and labels as provided using the below code.
"""

# use this code to upload training data or just use the colab upload button
from google.colab import files
files.upload()

"""## Step 2: Read the data

Change the path of the files as required.
"""

# Load the train images and labels
import pickle
train_x = pickle.load(open('/content/636_project1_train_images', 'rb'))
train_y = pickle.load(open('/content/636_project1_train_labels', 'rb'))

"""## Step 3: Visualize the images from teh data set"""

# View the data
import matplotlib.pyplot as plt
plt.imshow(train_x[9], cmap='Greys')
print(train_y[9])
print("The shape of label is:", train_y.shape)
print("The shape of image is:", train_x.shape)
print("Size of one images is:", train_x[0].shape)

"""## Method to pre process the data points."""

# data preprocessing

def preProcess(image_data):
  from tensorflow.python.ops.numpy_ops import np_config
  import numpy as np
  np_config.enable_numpy_behavior()
  # reshape 
  image_data = image_data.reshape(image_data.shape[0], 28, 28, 1)
  # convert to float
  image_data = image_data.astype('float32')
  # normalize the data
  image_data /= 255
  return image_data

# PreProcess the train_x data
train_x = preProcess(train_x)

# Divide the train_x and train_y into train and test data

test_x = train_x[50000:]
test_y = train_y[50000:]
train_x = train_x[:50000]
train_y = train_y[:50000]

print('train_x shape:', train_x.shape)
print('Number of images in train_x', train_x.shape[0])
print(train_x[0].shape)

"""##Step 5: Import the original Mnist dataset"""

from tensorflow.keras.datasets import mnist
(mnist_train_x, mnist_train_y), (mnist_test_x, mnist_test_y) = mnist.load_data()

mnist_train_x.shape
mnist_test_x.shape

"""## Step 6: Pre process the mnist data"""

mnist_train_x = preProcess(mnist_train_x)
mnist_test_x = preProcess(mnist_test_x)
input_shape = (28, 28, 1)

"""## Step 7: Define the model

I have tried to keep the model shape in a funnel shape as is observed in popular models like VGG etc.
This is the model which gave maximum accuracy till now.
"""

import tensorflow as tf
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(256, (3,3), activation='relu', input_shape=input_shape, use_bias=True),
    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', use_bias=True),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', use_bias=True),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Flatten(),
    
    tf.keras.layers.Dense(1024, activation = 'relu', use_bias=True),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(512, activation = 'relu', use_bias=True),
    tf.keras.layers.Dense(128, activation = 'relu', use_bias=True),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation='softmax', use_bias=True)
    
])

model.summary()

"""## Step 8: Train the model on the original mnist data

Save the best model 
"""

# mnist training
from keras.callbacks import EarlyStopping, ModelCheckpoint

# define callbacks
earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')
mcp_save = ModelCheckpoint('/content/sample_data/mnist_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')

# Compile the model
model.compile(optimizer='adam', 
              loss='sparse_categorical_crossentropy', 
              metrics=['accuracy'])

# Train the model
model.fit(x=mnist_train_x,y=mnist_train_y, epochs=50,batch_size =128,validation_split = 0.2, shuffle = True,callbacks=[earlyStopping,mcp_save])

# evaluate the model
from tensorflow import keras
model = keras.models.load_model('/content/sample_data/mnist_model.hdf5')
model.evaluate(mnist_test_x, mnist_test_y)

"""## Step 9: Train the model now with noisy data

I am using the best model trained on mnist data and then training it over the noisy data.
By doing so the model will now have already learnt to identify numbers and now just have learn to identify the noise.
"""

mnist_noise_save = ModelCheckpoint('/content/sample_data/mnist_noise.hdf5', save_best_only=True, monitor='val_loss', mode='min')
model.fit(x=train_x,y=train_y, epochs=50,batch_size =128,validation_split = 0.2, shuffle = True, callbacks=[earlyStopping, mnist_noise_save])

"""## Step 10: Evaluate the new model on the noisy data"""

model = keras.models.load_model('/content/sample_data/mnist_noise.hdf5')

model.evaluate(test_x, test_y)

"""# Testing Model on a different test data

## Step 1: Use the preProcess method to process the images before feeding into the trained model
"""

# Load the data and model
from google.colab import files
files.upload()

# Run this
def preProcess(image_data):
  from tensorflow.python.ops.numpy_ops import np_config
  import numpy as np
  np_config.enable_numpy_behavior()
  # reshape 
  image_data = image_data.reshape(image_data.shape[0], 28, 28, 1)
  # convert to float
  image_data = image_data.astype('float32')
  # normalize the data
  image_data /= 255
  return image_data

#read the data
import pickle
test_x = pickle.load(open('path', 'rb')) # give the path here
test_y = pickle.load(open('path', 'rb'))

# Preprocess the data so that it is ready to be given to the model
test_x = preProcess(test_x)

"""## Step 2: Load the model and evaluate"""

from tensorflow import keras
# Give the path of the saved model after upload
model = keras.models.load_model('model_path_goes_here')

model.evaluate(test_x, test_y)